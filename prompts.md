You are a Senior Principal Cloud Architect and Staff ML Engineer.

Your task is to generate a production-grade enterprise AI Ticketing System aligned with AWS Well-Architected Framework and modern MLOps standards.

The system must strictly follow clean architecture, domain-driven design (DDD), infrastructure-as-code, and production security standards.

========================================================
PROJECT CONTEXT
========================================================

We are building a Production-Grade AI Ticketing Platform with:

Cloud: AWS (Multi-AZ, Secure, HA)
Backend: FastAPI (Python 3.11)
Containerization: Docker
Orchestration: ECS Fargate
ML Platform: Amazon SageMaker (Training, Pipelines, Endpoints, Model Monitor)
Feature Store: SageMaker Feature Store (Online: DynamoDB, Offline: S3)
Vector DB: Amazon OpenSearch (kNN)
Streaming: MSK (Kafka)
CDC: AWS DMS
Lakehouse: S3 + Glue + Athena
LLM: Amazon Bedrock
Observability: CloudWatch, X-Ray
Security: IAM least privilege, KMS, VPC endpoints, WAF
IaC: Terraform (modular, environment-based)
CI/CD: GitHub Actions

Dataset Source: HuggingFace Customer Support Tickets

========================================================
ARCHITECTURE REQUIREMENTS
========================================================

1. Clean separation of:
   - API layer
   - Domain services
   - ML services
   - Feature store services
   - RAG services
   - Infrastructure modules

2. Implement:

   A) Classification Endpoint (SageMaker)
   B) Resolution Time Regression Endpoint
   C) Feature Store Online retrieval
   D) OpenSearch vector similarity search
   E) RAG using Bedrock
   F) Conversation memory (DynamoDB)
   G) CDC-triggered retraining pipeline

3. All components must:
   - Be production-safe
   - Include structured logging
   - Include proper exception handling
   - Include typing (mypy compatible)
   - Follow SOLID principles

========================================================
DELIVERABLES TO GENERATE
========================================================

Phase-by-phase code generation:

1Ô∏è‚É£ Project Folder Structure (enterprise standard)
2Ô∏è‚É£ FastAPI app (modular routers + dependency injection)
3Ô∏è‚É£ SageMaker service abstraction layer
4Ô∏è‚É£ Feature Store service (online retrieval + ingestion)
5Ô∏è‚É£ OpenSearch vector service
6Ô∏è‚É£ RAG orchestration layer
7Ô∏è‚É£ SageMaker Pipeline definition (training + register + conditional deploy)
8Ô∏è‚É£ Model Monitor configuration
9Ô∏è‚É£ Kafka consumer for CDC retraining
üîü Terraform modules:
   - VPC
   - ECS
   - SageMaker
   - MSK
   - OpenSearch
   - IAM
   - S3
   - Feature Store
1Ô∏è‚É£1Ô∏è‚É£ GitHub Actions CI/CD
1Ô∏è‚É£2Ô∏è‚É£ Docker production setup
1Ô∏è‚É£3Ô∏è‚É£ Observability configuration
1Ô∏è‚É£4Ô∏è‚É£ Security best practices implementation

========================================================
CODING STANDARDS
========================================================

- Use Python 3.11
- Pydantic v2
- Async FastAPI where appropriate
- boto3 with proper session handling
- Structured logging (JSON format)
- No hardcoded secrets
- Environment-based config
- 12-factor app principles
- Use dependency injection pattern
- Strict type hints everywhere

========================================================
INFRASTRUCTURE RULES
========================================================

Terraform must:
- Be modular
- Support dev/stage/prod environments
- Use remote state (S3 + DynamoDB locking)
- Use least-privilege IAM
- Encrypt everything with KMS
- Use private subnets for compute
- Use VPC endpoints where possible

========================================================
MLOPS STANDARDS
========================================================

- Training via SageMaker Pipelines
- Model Registry integration
- Conditional deployment
- Drift detection (PSI)
- Blue/Green deployment
- Automatic rollback capability
- Feature consistency between training and inference

========================================================
NON-FUNCTIONAL REQUIREMENTS
========================================================

- Handle 10M+ tickets
- Horizontally scalable
- Idempotent retraining triggers
- High availability
- Multi-AZ deployment
- Observability across app + ML + infra

========================================================
OUTPUT FORMAT
========================================================

Generate the project step-by-step.

Start with:

1) High-level implementation plan
2) Then generate folder structure
3) Then implement each module incrementally

Each file must:
- Be production-ready
- Include docstrings
- Include type hints
- Include logging
- Include error handling

Do NOT generate toy examples.
Do NOT simplify architecture.
Follow enterprise-grade standards.

Act as if this system will be deployed in a Fortune 500 production environment.
